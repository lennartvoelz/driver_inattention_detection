{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 20:15:54.045697: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 20:16:02.874251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "classes_train = pd.read_csv('../data/train/_classes.csv')\n",
    "classes_test = pd.read_csv('../data/test/_classes.csv')\n",
    "classes_valid = pd.read_csv('../data/valid/_classes.csv')\n",
    "\n",
    "pics_train = []\n",
    "pics_valid = []\n",
    "pics_test = []\n",
    "\n",
    "\n",
    "for filename in classes_train['filename']:\n",
    "    img = cv2.imread('../data/train/'+filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    pics_train.append(img)\n",
    "\n",
    "for filename in classes_valid['filename']:\n",
    "    img = cv2.imread('../data/valid/'+filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    pics_valid.append(img)\n",
    "\n",
    "for filename in classes_test['filename']:\n",
    "    img = cv2.imread('../data/test/'+filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    pics_test.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train = np.array(pics_train)\n",
    "pics_valid = np.array(pics_valid)\n",
    "pics_test = np.array(pics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(image):\n",
    "    \"\"\"\n",
    "    Crops the face from input image using Haar Cascade Classifier\n",
    "\n",
    "    Args:\n",
    "        image: image\n",
    "\n",
    "    Returns:\n",
    "        face: face image\n",
    "    \"\"\"\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(image, 1.1, 4)\n",
    "    if len(faces) == 0:\n",
    "        return image\n",
    "    for (x, y, w, h) in faces:\n",
    "        if y-30 >= 0 or x-30 >= 0 or y+h+30 < image.shape[0] or x+w+30 < image.shape[1]:\n",
    "            face = cv2.resize(image[y-30:y+30+h, x-30:x+w+30], (160, 160))\n",
    "        else:\n",
    "            face = cv2.resize(image[y:y+h, x:x+w], (160, 160))\n",
    "    return face\n",
    "\n",
    "\n",
    "# faces = []\n",
    "# for image in tqdm.tqdm(pics_train[:100]):\n",
    "#     face = crop_face(image)\n",
    "#     if face is not None:\n",
    "#         faces.append(face)\n",
    "\n",
    "# plt.imshow(pics_train[0])\n",
    "\n",
    "# test = crop_face(pics_train[0])\n",
    "\n",
    "# plt.imshow(test, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_crop(image):\n",
    "    return image[:,:,100:image.shape[2]-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cropped = hard_crop(pics_train)\n",
    "valid_cropped = hard_crop(pics_valid)\n",
    "test_cropped = hard_crop(pics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4642\n",
      "6180\n",
      "546\n",
      "2080\n",
      "428\n",
      "979\n"
     ]
    }
   ],
   "source": [
    "all_data_merged = pd.concat([classes_train, classes_test, classes_valid])\n",
    "print(all_data_merged[\" DangerousDriving\"].sum())\n",
    "print(all_data_merged[\" SafeDriving\"].sum())\n",
    "print(all_data_merged[\" Yawn\"].sum())\n",
    "print(all_data_merged[\" Distracted\"].sum())\n",
    "print(all_data_merged[\" Drinking\"].sum())\n",
    "print(all_data_merged[\" SleepyDriving\"].sum())\n",
    "\n",
    "ratio_dangerous = all_data_merged[\" DangerousDriving\"].sum() / all_data_merged[\" SafeDriving\"].sum()\n",
    "ratio_yawn = all_data_merged[\" Yawn\"].sum() / all_data_merged[\" SafeDriving\"].sum()\n",
    "ratio_distracted = all_data_merged[\" Distracted\"].sum() / all_data_merged[\" SafeDriving\"].sum()\n",
    "ratio_drinking = all_data_merged[\" Drinking\"].sum() / all_data_merged[\" SafeDriving\"].sum()\n",
    "ratio_sleepy = all_data_merged[\" SleepyDriving\"].sum() / all_data_merged[\" SafeDriving\"].sum()\n",
    "\n",
    "pics_per_pic = [1, 11, 3, 14, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_images(images, num_augmentations):\n",
    "    \"\"\"\n",
    "    Augment images using ImageDataGenerator\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): Images to augment\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Augmented images\n",
    "    \"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,  # Increased height shift range\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    augmented_images = []\n",
    "    for image in images:\n",
    "        image = np.expand_dims(image, 0)\n",
    "        i = 0\n",
    "        for i in range(num_augmentations):\n",
    "            augmented_images.append(train_datagen.random_transform(image))\n",
    "            i += 1\n",
    "            if i >= num_augmentations:\n",
    "                break\n",
    "    return augmented_images\n",
    "\n",
    "train_yawn_augmented = []\n",
    "train_yawn_data_augmented = pd.DataFrame(columns=classes_train.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_train[\" Yawn\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([train_cropped[i]], 11)\n",
    "        train_yawn_augmented.append(images)\n",
    "        for j in range(11):\n",
    "            train_yawn_data_augmented = pd.concat([train_yawn_data_augmented, classes_train.iloc[[i]]], ignore_index=True)\n",
    "            train_yawn_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 11  # Increment k after processing each set of images\n",
    "\n",
    "#do same for  Distracted, Drinking and SleepyDriving\n",
    "train_distracted_augmented = []\n",
    "train_distracted_data_augmented = pd.DataFrame(columns=classes_train.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_train[\" Distracted\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([train_cropped[i]], 3)\n",
    "        train_distracted_augmented.append(images)\n",
    "        for j in range(3):\n",
    "            train_distracted_data_augmented = pd.concat([train_distracted_data_augmented, classes_train.iloc[[i]]], ignore_index=True)\n",
    "            train_distracted_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 3  # Increment k after processing each set of images\n",
    "\n",
    "train_drinking_augmented = []\n",
    "train_drinking_data_augmented = pd.DataFrame(columns=classes_train.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_train[\" Drinking\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([train_cropped[i]], 14)\n",
    "        train_drinking_augmented.append(images)\n",
    "        for j in range(14):\n",
    "            train_drinking_data_augmented = pd.concat([train_drinking_data_augmented, classes_train.iloc[[i]]], ignore_index=True)\n",
    "            train_drinking_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 14  # Increment k after processing each set of images\n",
    "\n",
    "train_sleepy_augmented = []\n",
    "train_sleepy_data_augmented = pd.DataFrame(columns=classes_train.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_train[\" SleepyDriving\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([train_cropped[i]], 6)\n",
    "        train_sleepy_augmented.extend(images)\n",
    "        for j in range(6):\n",
    "            train_sleepy_data_augmented = pd.concat([train_sleepy_data_augmented, classes_train.iloc[[i]]], ignore_index=True)\n",
    "            train_sleepy_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 6  # Increment k after processing each set of images\n",
    "\n",
    "test_yawn_augmented = []\n",
    "test_yawn_data_augmented = pd.DataFrame(columns=classes_test.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_test[\" Yawn\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([test_cropped[i]], 11)\n",
    "        test_yawn_augmented.append(images)\n",
    "        for j in range(11):\n",
    "            test_yawn_data_augmented = pd.concat([test_yawn_data_augmented, classes_test.iloc[[i]]], ignore_index=True)\n",
    "            test_yawn_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 11  # Increment k after processing each set of images\n",
    "\n",
    "#do same for  Distracted, Drinking and SleepyDriving\n",
    "test_distracted_augmented = []\n",
    "test_distracted_data_augmented = pd.DataFrame(columns=classes_test.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_test[\" Distracted\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([test_cropped[i]], 3)\n",
    "        test_distracted_augmented.append(images)\n",
    "        for j in range(3):\n",
    "            test_distracted_data_augmented = pd.concat([test_distracted_data_augmented, classes_test.iloc[[i]]], ignore_index=True)\n",
    "            test_distracted_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 3  # Increment k after processing each set of images\n",
    "\n",
    "test_drinking_augmented = []\n",
    "test_drinking_data_augmented = pd.DataFrame(columns=classes_test.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_test[\" Drinking\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([test_cropped[i]], 14)\n",
    "        test_drinking_augmented.append(images)\n",
    "        for j in range(14):\n",
    "            test_drinking_data_augmented = pd.concat([test_drinking_data_augmented, classes_test.iloc[[i]]], ignore_index=True)\n",
    "            test_drinking_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 14  # Increment k after processing each set of images\n",
    "\n",
    "test_sleepy_augmented = []\n",
    "test_sleepy_data_augmented = pd.DataFrame(columns=classes_test.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_test[\" SleepyDriving\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([test_cropped[i]], 6)\n",
    "        test_sleepy_augmented.extend(images)\n",
    "        for j in range(6):\n",
    "            test_sleepy_data_augmented = pd.concat([test_sleepy_data_augmented, classes_test.iloc[[i]]], ignore_index=True)\n",
    "            test_sleepy_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 6  # Increment k after processing each set of images\n",
    "\n",
    "valid_yawn_augmented = []\n",
    "valid_yawn_data_augmented = pd.DataFrame(columns=classes_valid.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_valid[\" Yawn\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([valid_cropped[i]], 11)\n",
    "        valid_yawn_augmented.append(images)\n",
    "        for j in range(11):\n",
    "            valid_yawn_data_augmented = pd.concat([valid_yawn_data_augmented, classes_valid.iloc[[i]]], ignore_index=True)\n",
    "            valid_yawn_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 11  # Increment k after processing each set of images\n",
    "\n",
    "#do same for  Distracted, Drinking and SleepyDriving\n",
    "valid_distracted_augmented = []\n",
    "valid_distracted_data_augmented = pd.DataFrame(columns=classes_valid.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_valid[\" Distracted\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([valid_cropped[i]], 3)\n",
    "        valid_distracted_augmented.append(images)\n",
    "        for j in range(3):\n",
    "            valid_distracted_data_augmented = pd.concat([valid_distracted_data_augmented, classes_valid.iloc[[i]]], ignore_index=True)\n",
    "            valid_distracted_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 3  # Increment k after processing each set of images\n",
    "\n",
    "valid_drinking_augmented = []\n",
    "valid_drinking_data_augmented = pd.DataFrame(columns=classes_valid.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_valid[\" Drinking\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([valid_cropped[i]], 14)\n",
    "        valid_drinking_augmented.append(images)\n",
    "        for j in range(14):\n",
    "            valid_drinking_data_augmented = pd.concat([valid_drinking_data_augmented, classes_valid.iloc[[i]]], ignore_index=True)\n",
    "            valid_drinking_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 14  # Increment k after processing each set of images\n",
    "\n",
    "valid_sleepy_augmented = []\n",
    "valid_sleepy_data_augmented = pd.DataFrame(columns=classes_valid.columns)\n",
    "k = 0  # Initialize k before the loop\n",
    "\n",
    "for i, elem in enumerate(classes_valid[\" SleepyDriving\"]):\n",
    "    if elem == 1:\n",
    "        images = augment_images([valid_cropped[i]], 6)\n",
    "        valid_sleepy_augmented.extend(images)\n",
    "        for j in range(6):\n",
    "            valid_sleepy_data_augmented = pd.concat([valid_sleepy_data_augmented, classes_valid.iloc[[i]]], ignore_index=True)\n",
    "            valid_sleepy_data_augmented.at[k+j, \"filename\"] = f\"{k+j}\"\n",
    "        k += 6  # Increment k after processing each set of images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yawn_augmented = np.array(train_yawn_augmented).reshape(-1, 360, 440)\n",
    "train_distracted_augmented = np.array(train_distracted_augmented).reshape(-1, 360, 440)\n",
    "train_drinking_augmented = np.array(train_drinking_augmented).reshape(-1, 360, 440)\n",
    "train_sleepy_augmented = np.array(train_sleepy_augmented).reshape(-1, 360, 440)\n",
    "test_yawn_augmented = np.array(test_yawn_augmented).reshape(-1, 360, 440)\n",
    "test_distracted_augmented = np.array(test_distracted_augmented).reshape(-1, 360, 440)\n",
    "test_drinking_augmented = np.array(test_drinking_augmented).reshape(-1, 360, 440)\n",
    "test_sleepy_augmented = np.array(test_sleepy_augmented).reshape(-1, 360, 440)\n",
    "valid_yawn_augmented = np.array(valid_yawn_augmented).reshape(-1, 360, 440)\n",
    "valid_distracted_augmented = np.array(valid_distracted_augmented).reshape(-1, 360, 440)\n",
    "valid_drinking_augmented = np.array(valid_drinking_augmented).reshape(-1, 360, 440)\n",
    "valid_sleepy_augmented = np.array(valid_sleepy_augmented).reshape(-1, 360, 440)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4829/4829 [00:02<00:00, 1747.28it/s]\n",
      "100%|██████████| 5028/5028 [00:03<00:00, 1421.67it/s]\n",
      "100%|██████████| 4858/4858 [00:01<00:00, 3611.99it/s]\n",
      "100%|██████████| 4710/4710 [00:00<00:00, 5088.39it/s]\n",
      "100%|██████████| 286/286 [00:00<00:00, 4227.00it/s]\n",
      "100%|██████████| 456/456 [00:00<00:00, 4984.08it/s]\n",
      "100%|██████████| 350/350 [00:00<00:00, 4485.35it/s]\n",
      "100%|██████████| 414/414 [00:00<00:00, 4537.90it/s]\n",
      "100%|██████████| 891/891 [00:00<00:00, 5180.52it/s]\n",
      "100%|██████████| 756/756 [00:00<00:00, 5512.63it/s]\n",
      "100%|██████████| 784/784 [00:00<00:00, 7217.13it/s]\n",
      "100%|██████████| 750/750 [00:00<00:00, 12174.06it/s]\n"
     ]
    }
   ],
   "source": [
    "train_img_aug = []\n",
    "test_img_aug = []\n",
    "valid_img_aug = []\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(train_yawn_augmented))):\n",
    "    img = cv2.resize(train_yawn_augmented[pic], (192, 160))\n",
    "    train_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(train_distracted_augmented))):\n",
    "    img = cv2.resize(train_distracted_augmented[pic], (192, 160))\n",
    "    train_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(train_drinking_augmented))):\n",
    "    img = cv2.resize(train_drinking_augmented[pic], (192, 160))\n",
    "    train_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(train_sleepy_augmented))):\n",
    "    img = cv2.resize(train_sleepy_augmented[pic], (192, 160))\n",
    "    train_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(test_yawn_augmented))):\n",
    "    img = cv2.resize(test_yawn_augmented[pic], (192, 160))\n",
    "    test_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(test_distracted_augmented))):\n",
    "    img = cv2.resize(test_distracted_augmented[pic], (192, 160))\n",
    "    test_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(test_drinking_augmented))):\n",
    "    img = cv2.resize(test_drinking_augmented[pic], (192, 160))\n",
    "    test_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(test_sleepy_augmented))):\n",
    "    img = cv2.resize(test_sleepy_augmented[pic], (192, 160))\n",
    "    test_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(valid_yawn_augmented))):\n",
    "    img = cv2.resize(valid_yawn_augmented[pic], (192, 160))\n",
    "    valid_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(valid_distracted_augmented))):\n",
    "    img = cv2.resize(valid_distracted_augmented[pic], (192, 160))\n",
    "    valid_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(valid_drinking_augmented))):\n",
    "    img = cv2.resize(valid_drinking_augmented[pic], (192, 160))\n",
    "    valid_img_aug.append(img)\n",
    "\n",
    "for pic in tqdm.tqdm(range(len(valid_sleepy_augmented))):\n",
    "    img = cv2.resize(valid_sleepy_augmented[pic], (192, 160))\n",
    "    valid_img_aug.append(img)\n",
    "\n",
    "#concat the df in the same order\n",
    "train_data_aug = pd.concat([train_yawn_data_augmented, train_distracted_data_augmented, train_drinking_data_augmented, train_sleepy_data_augmented])\n",
    "test_data_aug = pd.concat([test_yawn_data_augmented, test_distracted_data_augmented, test_drinking_data_augmented, test_sleepy_data_augmented])\n",
    "valid_data_aug = pd.concat([valid_yawn_data_augmented, valid_distracted_data_augmented, valid_drinking_data_augmented, valid_sleepy_data_augmented])\n",
    "\n",
    "\n",
    "train_img_aug = np.array(train_img_aug)\n",
    "valid_img_aug = np.array(valid_img_aug)\n",
    "test_img_aug = np.array(test_img_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img = []\n",
    "# valid_img = []\n",
    "# test_img = []\n",
    "\n",
    "# for pic in tqdm.tqdm(range(len(train_cropped))):\n",
    "#     img = cv2.resize(train_cropped[pic], (192, 160))\n",
    "#     train_img.append(img)\n",
    "\n",
    "# for pic in tqdm.tqdm(range(len(valid_cropped))):\n",
    "#     img = cv2.resize(valid_cropped[pic], (192, 160))\n",
    "#     valid_img.append(img)\n",
    "\n",
    "# for pic in tqdm.tqdm(range(len(test_cropped))):\n",
    "#     img = cv2.resize(test_cropped[pic], (192, 160))\n",
    "#     test_img.append(img)\n",
    "\n",
    "# train_img = np.array(train_img)\n",
    "# valid_img = np.array(valid_img)\n",
    "# test_img = np.array(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_aug = train_img_aug.tolist()\n",
    "# valid_img_aug = valid_img_aug.tolist()\n",
    "# test_img_aug = test_img_aug.tolist()\n",
    "\n",
    "# json_train_aug = os.path.join('../data/augmented_data', 'train.json')\n",
    "# json_valid_aug = os.path.join('../data/augmented_data', 'valid.json')\n",
    "# json_test_aug =  os.path.join('../data/augmented_data', 'test.json')\n",
    "\n",
    "# # file_path = os.path.join('data', 'array.json')\n",
    "\n",
    "# with open(json_train_aug, 'w') as f:\n",
    "#     json.dump(train_img_aug, f)\n",
    "\n",
    "# with open(json_valid_aug, 'w') as f:\n",
    "#     json.dump(valid_img_aug, f)\n",
    "\n",
    "# with open(json_test_aug, 'w') as f:\n",
    "#     json.dump(test_img_aug, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safe the augmented dataframes\n",
    "train_data_aug.to_csv('../data/augmented_data/train.csv', index=False)\n",
    "valid_data_aug.to_csv('../data/augmented_data/valid.csv', index=False)\n",
    "test_data_aug.to_csv('../data/augmented_data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtest_img\u001b[49m[\u001b[38;5;241m34\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_img' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(test_img[34], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_img = train_img.tolist()\n",
    "valid_img = valid_img.tolist()\n",
    "test_img = test_img.tolist()\n",
    "\n",
    "json_train = os.path.join('../data', 'train.json')\n",
    "json_valid = os.path.join('../data', 'valid.json')\n",
    "json_test =  os.path.join('../data', 'test.json')\n",
    "\n",
    "# file_path = os.path.join('data', 'array.json')\n",
    "\n",
    "with open(json_train, 'w') as f:\n",
    "    json.dump(train_img, f)\n",
    "\n",
    "with open(json_valid, 'w') as f:\n",
    "    json.dump(valid_img, f)\n",
    "\n",
    "with open(json_test, 'w') as f:\n",
    "    json.dump(test_img, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
